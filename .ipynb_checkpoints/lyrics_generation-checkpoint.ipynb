{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(\"lirik_lp.txt\", 'r', encoding='utf8') as f:\n",
    "    lirik = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', ':', ';', '?', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'á', 'ç', '—', '’', '…']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(lirik)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(lirik) - SEQUENCE_LENGTH):\n",
    "    sequences.append(lirik[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(lirik[i + SEQUENCE_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(chars)) \n",
    "index_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 128)               94720     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 56)                7224      \n",
      "=================================================================\n",
      "Total params: 118,456\n",
      "Trainable params: 118,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 57s - loss: 2.5550\n",
      "Epoch 2/30\n",
      " - 54s - loss: 2.0142\n",
      "Epoch 3/30\n",
      " - 55s - loss: 1.7943\n",
      "Epoch 4/30\n",
      " - 54s - loss: 1.6525\n",
      "Epoch 5/30\n",
      " - 55s - loss: 1.5460\n",
      "Epoch 6/30\n",
      " - 54s - loss: 1.4577\n",
      "Epoch 7/30\n",
      " - 54s - loss: 1.3777\n",
      "Epoch 8/30\n",
      " - 54s - loss: 1.3073\n",
      "Epoch 9/30\n",
      " - 55s - loss: 1.2448\n",
      "Epoch 10/30\n",
      " - 55s - loss: 1.1842\n",
      "Epoch 11/30\n",
      " - 55s - loss: 1.1312\n",
      "Epoch 12/30\n",
      " - 55s - loss: 1.0815\n",
      "Epoch 13/30\n",
      " - 54s - loss: 1.0346\n",
      "Epoch 14/30\n",
      " - 55s - loss: 0.9923\n",
      "Epoch 15/30\n",
      " - 54s - loss: 0.9531\n",
      "Epoch 16/30\n",
      " - 55s - loss: 0.9132\n",
      "Epoch 17/30\n",
      " - 54s - loss: 0.8788\n",
      "Epoch 18/30\n",
      " - 54s - loss: 0.8457\n",
      "Epoch 19/30\n",
      " - 54s - loss: 0.8145\n",
      "Epoch 20/30\n",
      " - 55s - loss: 0.7843\n",
      "Epoch 21/30\n",
      " - 55s - loss: 0.7570\n",
      "Epoch 22/30\n",
      " - 55s - loss: 0.7315\n",
      "Epoch 23/30\n",
      " - 55s - loss: 0.7073\n",
      "Epoch 24/30\n",
      " - 55s - loss: 0.6814\n",
      "Epoch 25/30\n",
      " - 54s - loss: 0.6612\n",
      "Epoch 26/30\n",
      " - 55s - loss: 0.6408\n",
      "Epoch 27/30\n",
      " - 55s - loss: 0.6195\n",
      "Epoch 28/30\n",
      " - 55s - loss: 0.6033\n",
      "Epoch 29/30\n",
      " - 55s - loss: 0.5839\n",
      "Epoch 30/30\n",
      " - 55s - loss: 0.5695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f15c664eda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lirik_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0721 00:12:19.181815 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0721 00:12:19.451221 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0721 00:12:19.500036 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0721 00:12:21.294093 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0721 00:12:21.297931 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0721 00:12:23.013283 140082756704064 deprecation_wrapper.py:119] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0721 00:12:23.615350 140082756704064 deprecation.py:323] From /home/golok/anaconda3/envs/machinelearning/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"lirik_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_index(preds):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    return np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Generating with seed: \"blame me for my past, but i just want to see you\n",
      "i\"\n",
      "blame me for my past, but i just want to see you\n",
      "if i could change, i would take back the pain i can't become so sing\n",
      "a little son reals get what i've done\n",
      "\n",
      "\n",
      "\n",
      "tell me say goodbye to my sead\n",
      "smins i can't stop the same\n",
      "so i'm like i can't stop the sids and rise\n",
      "\n",
      "\n",
      "\n",
      "i wanna fall wide awake what i've done\n",
      "\n",
      "\n",
      "\n",
      "tell me say goint like you\n",
      "(cause you convered\n",
      "away\n",
      "never gotsa away from me)\n",
      "high voltage\n",
      "the broken petsion of clounsced of clounds\n",
      "\n",
      "a little "
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "sentence = \"Blame me for my past, but I just want to see you\\nI\"\n",
    "sentence = sentence.lower()\n",
    "generated += sentence\n",
    "\n",
    "print('----- Generating with seed: \"' + sentence + '\"')\n",
    "print(generated, end='')\n",
    "\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_to_index[char]] = 1.\n",
    "\n",
    "    predictions = model.predict(x, verbose=0)[0]\n",
    "    next_index = get_highest_index(predictions)\n",
    "    next_char = index_to_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    print(next_char, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
